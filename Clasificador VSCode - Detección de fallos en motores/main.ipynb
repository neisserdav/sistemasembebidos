{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando un modelo de IA usando datos EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerias necesaria\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import lite\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de los sensores empleados.\n",
    "emg_columns = [\"ax\", \"ay\", \"az\"]\n",
    "\n",
    "# Asignar a cada carpeta un identificador correspondiente a una tarea motora.\n",
    "FOLDER_2_LABEL = {\"task1\": 0, \"task2\": 1, \"task3\": 2}\n",
    "\n",
    "# Frecuencia de Muestreo de la señal.\n",
    "ORIGINAL_FREC = 100 # Hz\n",
    "# Tiempo de muestreo de un sample.\n",
    "SAMPLE_TIME = 1\n",
    "TOTAL_DATA = int(SAMPLE_TIME*ORIGINAL_FREC)\n",
    "\n",
    "# Path donde se almacenan los datos.\n",
    "MAIN_PATH = \"data\"\n",
    "\n",
    "# Path para guardar las características calculadas.\n",
    "FEATURES_PATH = \"Features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(df: pd.DataFrame, window_size: int):\n",
    "    \"\"\"\n",
    "    Filtrar la señal usando el método de la media móvil.\n",
    "    Params:\n",
    "        df: contiene los datos emg, siendo\n",
    "            cada columna el registro de un\n",
    "            sensor. \n",
    "        window_size: tamano de la ventana móvil.\n",
    "    Return:\n",
    "        df_filtered (Dataframe): contiene los datos EMG \n",
    "                                 filtrados por columna.\n",
    "    \"\"\"\n",
    "    df_filtered = df.rolling(window_size).mean()\n",
    "    df_filtered.dropna(inplace=True)\n",
    "    return df_filtered\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Normalizar las columnas aplicando el \n",
    "    método de normalización min-max.\n",
    "    \"\"\"\n",
    "    df_normalized = (df-df.min())/(df.max()-df.min())\n",
    "    return df_normalized\n",
    "\n",
    "def calculate_features(df: pd.DataFrame, label: int):\n",
    "    \"\"\"\n",
    "    Calcula las características de la señal por sensor,\n",
    "    usando el método del valor RMS.\n",
    "    Params:\n",
    "        df: contiene los datos emg, siendo\n",
    "            cada columna el registro de un\n",
    "            sensor.\n",
    "        label: el identificador de la tarea motora a\n",
    "               la que corresponde esa señal.\n",
    "    Return:\n",
    "        features_list (list): contiene el label de la\n",
    "                              señal y las características. \n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    for sensor in emg_columns:\n",
    "        for i in range(0, 100, 20):\n",
    "            features_list.append(np.sqrt(np.mean(df.iloc[i:i+20][sensor]**2)))\n",
    "    features_list.insert(0, label)\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado - Normalización - Extracción de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Para calcular y usar el valor RMS de una senal como entrada de un modelo, se debe procurar escoger una ventana no tan grande, ya que la senal podría dejar de ser representativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neiss\\AppData\\Local\\Temp\\ipykernel_20280\\1537125041.py:21: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(file_path, names=emg_columns, index_col=False)\n"
     ]
    }
   ],
   "source": [
    "# El tamano de la ventana para calcular las características.\n",
    "WINDOW_RMS = 20\n",
    "\n",
    "# El tamano de la ventana inicial debe ser divisible para el tamano de la ventana RMS.\n",
    "assert(TOTAL_DATA % WINDOW_RMS == 0)\n",
    "\n",
    "# Generar una lista que contenga los nombres de las características a calcular.\n",
    "features_column = ['RMS' + str(x) + '_' + sensor for sensor in emg_columns for x in range(WINDOW_RMS,TOTAL_DATA+WINDOW_RMS, WINDOW_RMS)]\n",
    "features_column.insert(0,\"Label\")\n",
    "\n",
    "# Inicializar el Dataframe que contendrá las características calculadas más adelante.\n",
    "df_features = pd.DataFrame(columns=features_column)\n",
    "\n",
    "# Recorrer cada carpeta.\n",
    "for folder in os.listdir(MAIN_PATH):\n",
    "    folder_path = os.path.join(MAIN_PATH, folder)\n",
    "    # Recorrer cada archivo de la carpeta.\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Leer las senales EMG.\n",
    "        df = pd.read_csv(file_path, names=emg_columns, index_col=False)\n",
    "        # Filtrar las senales EMG.\n",
    "        df_filtered = filter_signal(df, 2)\n",
    "        # Normalizar las senales EMG.\n",
    "        df_norm = normalize_columns(df_filtered)\n",
    "        # Calcular las características del respectivo archivo.\n",
    "        features = calculate_features(df_norm, FOLDER_2_LABEL[folder])\n",
    "        # Agregar las características calculadas al Dataframe df_features.\n",
    "        df_features.loc[len(df_features)] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el Dataframe con las características.\n",
    "df_features.to_csv(FEATURES_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una semilla.\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Establecer el porcentaje para dividir la data.\n",
    "TRAIN_SPLIT = 0.6\n",
    "VALID_TEST_SPLIT = 0.2\n",
    "assert(TRAIN_SPLIT + (2*VALID_TEST_SPLIT) == 1)\n",
    "\n",
    "# Definir la taza de aprendizaje.\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Definir el número de épocas.\n",
    "EPOCHS = 200\n",
    "\n",
    "# Definir el tamaño del batch.\n",
    "BATCH_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo con características de las señales EMG.\n",
    "features_df = pd.read_csv(FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna a tipo int.\n",
    "features_df[\"Label\"] = features_df[\"Label\"].astype(int)\n",
    "# Asegurarnos de no introducir datos vacíos.\n",
    "features_df.dropna(inplace=True)\n",
    "# Hacer un shuffle a los datos.\n",
    "features = features_df.sample(frac=1, random_state=RANDOM_STATE)\n",
    "# Convertir a un arreglo de numpy (ya que el modelo trabaja con este tipo de datos).\n",
    "features = features.to_numpy()\n",
    "\n",
    "# Separar los datos entre el target (el id de la tarea motora) y las características.\n",
    "# Nota: En este caso en específico se usa la función to_categorical, ya que \n",
    "# la función de pérdida que se usó en el modelo requiere de variables categóricas.\n",
    "y_values = keras.utils.to_categorical(features[:,0], num_classes=4)\n",
    "x_values = features[:,1:].astype('float32')\n",
    "\n",
    "# Separar los datos en TRAINING, TESTING Y VALIDATION.\n",
    "TRAIN_SPLIT =  int(TRAIN_SPLIT * features.shape[0])\n",
    "TEST_SPLIT = int(VALID_TEST_SPLIT * features.shape[0] + TRAIN_SPLIT)\n",
    "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "# Asegurar que la división de los datos fue exitosa.\n",
    "assert(x_train.shape[0] + x_test.shape[0] + x_validate.shape[0] == features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura del modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (x_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(30, input_shape = (x_train.shape[1],),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 3s 292ms/step - loss: 0.1692 - accuracy: 0.9333 - recall_43: 0.9333 - precision_43: 0.9385 - val_loss: 1.2595 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2405 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 1.3401 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0986 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.9507 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1239 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.7637 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0658 - accuracy: 0.9778 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 0.6769 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1506 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.7149 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0950 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.9713 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1233 - accuracy: 0.9611 - recall_43: 0.9556 - precision_43: 0.9663 - val_loss: 1.1680 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0642 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.2625 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1125 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.1589 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0833 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.9804 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1026 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.8314 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8475\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0688 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9888 - val_loss: 0.7752 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1362 - accuracy: 0.9389 - recall_43: 0.9333 - precision_43: 0.9385 - val_loss: 0.7370 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1361 - accuracy: 0.9389 - recall_43: 0.9333 - precision_43: 0.9385 - val_loss: 0.7622 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1081 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.7818 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1000 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.7999 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1315 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 0.8446 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0951 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 0.9900 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0617 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.1526 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0863 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.2828 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0718 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9888 - val_loss: 1.3317 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0934 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.3026 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0663 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.2820 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0728 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.2952 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0378 - accuracy: 0.9944 - recall_43: 0.9944 - precision_43: 0.9944 - val_loss: 1.3356 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0402 - accuracy: 0.9833 - recall_43: 0.9778 - precision_43: 0.9832 - val_loss: 1.3398 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0792 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.3239 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0829 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9665 - val_loss: 1.3041 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0814 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.2357 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1117 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.1727 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0688 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 1.1643 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0982 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 1.1408 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0724 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.1192 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0944 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 1.0952 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1173 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0712 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0460 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.0566 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0892 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0363 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1447 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 1.0317 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0816 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0404 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0968 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.1293 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1088 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.1858 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1228 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 1.1629 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1394 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 1.1171 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0558 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.0825 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0517 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.0613 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0982 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0549 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0610 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.0351 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0845 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.0336 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2183 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 0.9761 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1392 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.9449 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1091 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.9657 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7966\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1363 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 1.1594 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1300 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 1.3219 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2077 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.4930 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1424 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.5666 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1494 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.3400 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0942 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.0654 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1085 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9665 - val_loss: 0.8631 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1182 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.7183 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0844 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.7616 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0615 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.9307 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1277 - accuracy: 0.9667 - recall_43: 0.9611 - precision_43: 0.9719 - val_loss: 1.1499 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0659 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.3120 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0458 - accuracy: 0.9944 - recall_43: 0.9944 - precision_43: 0.9944 - val_loss: 1.3776 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0747 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.1266 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1381 - accuracy: 0.9333 - recall_43: 0.9333 - precision_43: 0.9333 - val_loss: 0.6463 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1042 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.5329 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1241 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 0.4882 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1660 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.3941 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1453 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9494 - val_loss: 0.3697 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1547 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.3631 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1333 - accuracy: 0.9500 - recall_43: 0.9444 - precision_43: 0.9497 - val_loss: 0.3219 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0728 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.3133 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1661 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 0.3261 - val_accuracy: 0.9000 - val_recall_43: 0.9000 - val_precision_43: 0.9000\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1129 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 0.3234 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2000 - accuracy: 0.9389 - recall_43: 0.9333 - precision_43: 0.9385 - val_loss: 0.3544 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1282 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.4139 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1438 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9607 - val_loss: 0.4525 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1469 - accuracy: 0.9278 - recall_43: 0.9278 - precision_43: 0.9278 - val_loss: 0.4260 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0723 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.3488 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1145 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.2403 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1687 - accuracy: 0.9278 - recall_43: 0.9278 - precision_43: 0.9278 - val_loss: 0.2569 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1409 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.3027 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0741 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.3673 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1216 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 0.5000 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2171 - accuracy: 0.9222 - recall_43: 0.9222 - precision_43: 0.9222 - val_loss: 0.6883 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2330 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.8190 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0734 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 0.8766 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1505 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 0.9386 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1415 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9665 - val_loss: 0.9517 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0612 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.9526 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0732 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.9912 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1618 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.0685 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0902 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.9907 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0551 - accuracy: 0.9889 - recall_43: 0.9833 - precision_43: 0.9888 - val_loss: 0.6966 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1324 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.6604 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1634 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 0.9593 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0617 - accuracy: 0.9778 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 1.2188 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1745 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 1.2133 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1191 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9719 - val_loss: 1.0164 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1430 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.8288 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1025 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.7235 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1606 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.6566 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1156 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.6663 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1645 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.8050 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0770 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 1.0379 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1133 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.2077 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1265 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.1072 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1151 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 0.9177 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0788 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.7909 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1082 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 0.7544 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1276 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.8548 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1615 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9497 - val_loss: 0.9562 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0754 - accuracy: 0.9778 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 1.0467 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1072 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9609 - val_loss: 1.2931 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1292 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 1.5632 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1522 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 1.0766 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0979 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.6648 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1552 - accuracy: 0.9333 - recall_43: 0.9333 - precision_43: 0.9385 - val_loss: 0.4572 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1059 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9665 - val_loss: 0.4310 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1290 - accuracy: 0.9500 - recall_43: 0.9500 - precision_43: 0.9500 - val_loss: 0.4288 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0931 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.3963 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0869 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.3898 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1562 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.3934 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0805 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.4025 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0811 - accuracy: 0.9722 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 0.4108 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0875 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.4051 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0710 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.4107 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0696 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.4066 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0869 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.3928 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1316 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 0.4063 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0954 - accuracy: 0.9833 - recall_43: 0.9778 - precision_43: 0.9832 - val_loss: 0.4288 - val_accuracy: 0.8833 - val_recall_43: 0.8833 - val_precision_43: 0.8833\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0813 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.4770 - val_accuracy: 0.8667 - val_recall_43: 0.8667 - val_precision_43: 0.8667\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1013 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.5360 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1204 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.6353 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0610 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.7665 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0819 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.8277 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0945 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.8064 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0661 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.7805 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0928 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 0.7171 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1125 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.6719 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1504 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.6763 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1186 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 0.7141 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0651 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.7470 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0664 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 0.8365 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1643 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 0.9102 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0941 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0523 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1170 - accuracy: 0.9611 - recall_43: 0.9556 - precision_43: 0.9663 - val_loss: 1.2841 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1078 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.3271 - val_accuracy: 0.8500 - val_recall_43: 0.8500 - val_precision_43: 0.8500\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0571 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.2774 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1471 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.1708 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0846 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.0992 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0769 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.0250 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0550 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 0.9550 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0823 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 0.9450 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0924 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.0028 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0841 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.1379 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0910 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.2467 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0447 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.3358 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1335 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.3605 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0869 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.3476 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0965 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.3511 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0792 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.3071 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0515 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.2815 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1728 - accuracy: 0.9722 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 1.2608 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1522 - accuracy: 0.9389 - recall_43: 0.9389 - precision_43: 0.9389 - val_loss: 1.1664 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1334 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9444 - val_loss: 1.1248 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0762 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9721 - val_loss: 1.1027 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0335 - accuracy: 0.9944 - recall_43: 0.9944 - precision_43: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1223 - accuracy: 0.9444 - recall_43: 0.9444 - precision_43: 0.9497 - val_loss: 1.1540 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1322 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.1600 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0521 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.1473 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1093 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.1846 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0952 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.3197 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0743 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.4539 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0725 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.5806 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0846 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.6004 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0599 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9888 - val_loss: 1.5934 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0674 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.5902 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0861 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.5295 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0857 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.3895 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0743 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.3556 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0574 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.4034 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0425 - accuracy: 0.9889 - recall_43: 0.9833 - precision_43: 0.9888 - val_loss: 1.5674 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1169 - accuracy: 0.9500 - recall_43: 0.9444 - precision_43: 0.9551 - val_loss: 1.6572 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0726 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.6270 - val_accuracy: 0.7333 - val_recall_43: 0.7333 - val_precision_43: 0.7333\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0920 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.5738 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0716 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.5466 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2252 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.5271 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0881 - accuracy: 0.9611 - recall_43: 0.9611 - precision_43: 0.9611 - val_loss: 1.5346 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0719 - accuracy: 0.9667 - recall_43: 0.9667 - precision_43: 0.9667 - val_loss: 1.5943 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0568 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.6622 - val_accuracy: 0.7333 - val_recall_43: 0.7333 - val_precision_43: 0.7333\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0486 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.6705 - val_accuracy: 0.7333 - val_recall_43: 0.7333 - val_precision_43: 0.7333\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0761 - accuracy: 0.9778 - recall_43: 0.9722 - precision_43: 0.9777 - val_loss: 1.7017 - val_accuracy: 0.7500 - val_recall_43: 0.7500 - val_precision_43: 0.7500\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0466 - accuracy: 0.9889 - recall_43: 0.9889 - precision_43: 0.9889 - val_loss: 1.6978 - val_accuracy: 0.7667 - val_recall_43: 0.7667 - val_precision_43: 0.7667\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0642 - accuracy: 0.9722 - recall_43: 0.9722 - precision_43: 0.9722 - val_loss: 1.4438 - val_accuracy: 0.7833 - val_recall_43: 0.7833 - val_precision_43: 0.7833\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0460 - accuracy: 0.9833 - recall_43: 0.9833 - precision_43: 0.9833 - val_loss: 1.2152 - val_accuracy: 0.8000 - val_recall_43: 0.8000 - val_precision_43: 0.8000\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0681 - accuracy: 0.9778 - recall_43: 0.9778 - precision_43: 0.9778 - val_loss: 1.1185 - val_accuracy: 0.8167 - val_recall_43: 0.8167 - val_precision_43: 0.8167\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1403 - accuracy: 0.9556 - recall_43: 0.9556 - precision_43: 0.9556 - val_loss: 1.0203 - val_accuracy: 0.8333 - val_recall_43: 0.8333 - val_precision_43: 0.8333\n",
      "Total training time: 15.965867519378662s\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9162 - accuracy: 0.7833 - recall_43: 0.7833 - precision_43: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# Definir la función de optimización y sus hiperparámetros.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "# Definir la función de pérdida y compilar el modelo.\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Entrenar el modelo\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                            validation_data=(x_validate, y_validate))\n",
    "stop = time.time()\n",
    "print(f\"Total training time: {stop - start}s\")\n",
    "test_results = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testear el modelo\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Definir la matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "df_cm = pd.DataFrame(cm, range(cm.shape[0]), range(cm.shape[0]))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 9})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\neiss\\AppData\\Local\\Temp\\tmpx0k1celx\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14752"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la dirección donde se guardará los datos del modelo.\n",
    "MODELS_DIR = 'models/'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "\n",
    "# Crear la carpeta sino existe.\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "\n",
    "# Guardar el modelo.\n",
    "model.save(MODELS_DIR)\n",
    "\n",
    "# Convertir el modelo a Tensorflow Lite.\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Guardar el modelo .tflite\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)\n",
    "\n",
    "# Correr esta linea de código en Linux.\n",
    "# Esto se hace para transformar el modelo a un archivo fuente C (https://www.tensorflow.org/lite/microcontrollers/build_convert?hl=es-419#model_conversion)\n",
    "# xxd -i converted_model.tflite > model_data.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "217a05b0ff8d294ed2aa23a3dc69be997e5e448d63a17da996bf859fbae026a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
